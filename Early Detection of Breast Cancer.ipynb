{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56ce9f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (569, 30)\n",
      "Class Distribution:\n",
      "Benign (1): 357\n",
      "Malignant (0): 212\n",
      "Training set shape: (455, 30)\n",
      "Test set shape: (114, 30)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                           f1_score, confusion_matrix, classification_report, roc_auc_score, roc_curve)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv1D, GlobalMaxPooling1D, Reshape\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Create DataFrame for better understanding\n",
    "df = pd.DataFrame(X, columns=data.feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "print(\"Dataset Shape:\", X.shape)\n",
    "print(\"Class Distribution:\")\n",
    "print(\"Benign (1):\", sum(y == 1))\n",
    "print(\"Malignant (0):\", sum(y == 0))\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set shape: {X_train_scaled.shape}\")\n",
    "print(f\"Test set shape: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f89afed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"1. LOGISTIC REGRESSION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "lr_pred = lr_model.predict(X_test_scaled)\n",
    "lr_pred_proba = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Performance metrics\n",
    "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
    "lr_precision = precision_score(y_test, lr_pred)\n",
    "lr_recall = recall_score(y_test, lr_pred)\n",
    "lr_f1 = f1_score(y_test, lr_pred)\n",
    "lr_auc = roc_auc_score(y_test, lr_pred_proba)\n",
    "\n",
    "print(f\"Accuracy: {lr_accuracy:.4f}\")\n",
    "print(f\"Precision: {lr_precision:.4f}\")\n",
    "print(f\"Recall: {lr_recall:.4f}\")\n",
    "print(f\"F1-Score: {lr_f1:.4f}\")\n",
    "print(f\"AUC-ROC: {lr_auc:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, lr_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209b386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n2. RANDOM FOREST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "rf_pred = rf_model.predict(X_test_scaled)\n",
    "rf_pred_proba = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Performance metrics\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "rf_precision = precision_score(y_test, rf_pred)\n",
    "rf_recall = recall_score(y_test, rf_pred)\n",
    "rf_f1 = f1_score(y_test, rf_pred)\n",
    "rf_auc = roc_auc_score(y_test, rf_pred_proba)\n",
    "\n",
    "print(f\"Accuracy: {rf_accuracy:.4f}\")\n",
    "print(f\"Precision: {rf_precision:.4f}\")\n",
    "print(f\"Recall: {rf_recall:.4f}\")\n",
    "print(f\"F1-Score: {rf_f1:.4f}\")\n",
    "print(f\"AUC-ROC: {rf_auc:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, rf_pred))\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': data.feature_names,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Important Features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4df3468",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n3. SUPPORT VECTOR MACHINE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "svm_model = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "svm_pred = svm_model.predict(X_test_scaled)\n",
    "svm_pred_proba = svm_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Performance metrics\n",
    "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
    "svm_precision = precision_score(y_test, svm_pred)\n",
    "svm_recall = recall_score(y_test, svm_pred)\n",
    "svm_f1 = f1_score(y_test, svm_pred)\n",
    "svm_auc = roc_auc_score(y_test, svm_pred_proba)\n",
    "\n",
    "print(f\"Accuracy: {svm_accuracy:.4f}\")\n",
    "print(f\"Precision: {svm_precision:.4f}\")\n",
    "print(f\"Recall: {svm_recall:.4f}\")\n",
    "print(f\"F1-Score: {svm_f1:.4f}\")\n",
    "print(f\"AUC-ROC: {svm_auc:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, svm_pred))\n",
    "# Multi-Layer Perceptron\n",
    "print(\"\\n4. MULTI-LAYER PERCEPTRON (NEURAL NETWORK)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)\n",
    "mlp_model.fit(X_train_scaled, y_train)\n",
    "mlp_pred = mlp_model.predict(X_test_scaled)\n",
    "mlp_pred_proba = mlp_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Performance metrics\n",
    "mlp_accuracy = accuracy_score(y_test, mlp_pred)\n",
    "mlp_precision = precision_score(y_test, mlp_pred)\n",
    "mlp_recall = recall_score(y_test, mlp_pred)\n",
    "mlp_f1 = f1_score(y_test, mlp_pred)\n",
    "mlp_auc = roc_auc_score(y_test, mlp_pred_proba)\n",
    "\n",
    "print(f\"Accuracy: {mlp_accuracy:.4f}\")\n",
    "print(f\"Precision: {mlp_precision:.4f}\")\n",
    "print(f\"Recall: {mlp_recall:.4f}\")\n",
    "print(f\"F1-Score: {mlp_f1:.4f}\")\n",
    "print(f\"AUC-ROC: {mlp_auc:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, mlp_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482e2a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Neural Network with TensorFlow\n",
    "print(\"\\n5. DEEP NEURAL NETWORK (TensorFlow)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Build the model\n",
    "tf.random.set_seed(42)\n",
    "dnn_model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "dnn_model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = dnn_model.fit(X_train_scaled, y_train,\n",
    "                       epochs=100,\n",
    "                       batch_size=32,\n",
    "                       validation_split=0.2,\n",
    "                       verbose=0)\n",
    "\n",
    "# Make predictions\n",
    "dnn_pred_proba = dnn_model.predict(X_test_scaled).flatten()\n",
    "dnn_pred = (dnn_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Performance metrics\n",
    "dnn_accuracy = accuracy_score(y_test, dnn_pred)\n",
    "dnn_precision = precision_score(y_test, dnn_pred)\n",
    "dnn_recall = recall_score(y_test, dnn_pred)\n",
    "dnn_f1 = f1_score(y_test, dnn_pred)\n",
    "dnn_auc = roc_auc_score(y_test, dnn_pred_proba)\n",
    "\n",
    "print(f\"Accuracy: {dnn_accuracy:.4f}\")\n",
    "print(f\"Precision: {dnn_precision:.4f}\")\n",
    "print(f\"Recall: {dnn_recall:.4f}\")\n",
    "print(f\"F1-Score: {dnn_f1:.4f}\")\n",
    "print(f\"AUC-ROC: {dnn_auc:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, dnn_pred))\n",
    "# 1D CNN (adapted for tabular data)\n",
    "print(\"\\n6. 1D CONVOLUTIONAL NEURAL NETWORK\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Reshape data for CNN (treat features as sequence)\n",
    "X_train_cnn = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)\n",
    "X_test_cnn = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
    "\n",
    "# Build CNN model\n",
    "tf.random.set_seed(42)\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train_scaled.shape[1], 1)),\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "cnn_history = cnn_model.fit(X_train_cnn, y_train,\n",
    "                           epochs=100,\n",
    "                           batch_size=32,\n",
    "                           validation_split=0.2,\n",
    "                           verbose=0)\n",
    "\n",
    "# Make predictions\n",
    "cnn_pred_proba = cnn_model.predict(X_test_cnn).flatten()\n",
    "cnn_pred = (cnn_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Performance metrics\n",
    "cnn_accuracy = accuracy_score(y_test, cnn_pred)\n",
    "cnn_precision = precision_score(y_test, cnn_pred)\n",
    "cnn_recall = recall_score(y_test, cnn_pred)\n",
    "cnn_f1 = f1_score(y_test, cnn_pred)\n",
    "cnn_auc = roc_auc_score(y_test, cnn_pred_proba)\n",
    "\n",
    "print(f\"Accuracy: {cnn_accuracy:.4f}\")\n",
    "print(f\"Precision: {cnn_precision:.4f}\")\n",
    "print(f\"Recall: {cnn_recall:.4f}\")\n",
    "print(f\"F1-Score: {cnn_f1:.4f}\")\n",
    "print(f\"AUC-ROC: {cnn_auc:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, cnn_pred))\n",
    "# Create comparison dataframe\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'SVM', 'MLP', 'Deep NN', '1D CNN'],\n",
    "    'Accuracy': [lr_accuracy, rf_accuracy, svm_accuracy, mlp_accuracy, dnn_accuracy, cnn_accuracy],\n",
    "    'Precision': [lr_precision, rf_precision, svm_precision, mlp_precision, dnn_precision, cnn_precision],\n",
    "    'Recall': [lr_recall, rf_recall, svm_recall, mlp_recall, dnn_recall, cnn_recall],\n",
    "    'F1-Score': [lr_f1, rf_f1, svm_f1, mlp_f1, dnn_f1, cnn_f1],\n",
    "    'AUC-ROC': [lr_auc, rf_auc, svm_auc, mlp_auc, dnn_auc, cnn_auc]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(results.round(4))\n",
    "\n",
    "# Find best model for each metric\n",
    "print(\"\\nBEST PERFORMING MODELS:\")\n",
    "print(\"-\" * 30)\n",
    "for metric in ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']:\n",
    "    best_idx = results[metric].idxmax()\n",
    "    best_model = results.loc[best_idx, 'Model']\n",
    "    best_score = results.loc[best_idx, metric]\n",
    "    print(f\"{metric}: {best_model} ({best_score:.4f})\")\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Performance comparison\n",
    "plt.subplot(2, 2, 1)\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']\n",
    "x = np.arange(len(results))\n",
    "width = 0.15\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    plt.bar(x + i*width, results[metric], width, label=metric, alpha=0.8)\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.xticks(x + width*2, results['Model'], rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# ROC Curves\n",
    "plt.subplot(2, 2, 2)\n",
    "models_data = [\n",
    "    ('Logistic Regression', y_test, lr_pred_proba),\n",
    "    ('Random Forest', y_test, rf_pred_proba),\n",
    "    ('SVM', y_test, svm_pred_proba),\n",
    "    ('MLP', y_test, mlp_pred_proba),\n",
    "    ('Deep NN', y_test, dnn_pred_proba),\n",
    "    ('1D CNN', y_test, cnn_pred_proba)\n",
    "]\n",
    "\n",
    "for name, y_true, y_prob in models_data:\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC={auc:.3f})', linewidth=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Training history for deep learning models\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(history.history['accuracy'], label='DNN Train Accuracy', linewidth=2)\n",
    "plt.plot(history.history['val_accuracy'], label='DNN Val Accuracy', linewidth=2)\n",
    "plt.plot(cnn_history.history['accuracy'], label='CNN Train Accuracy', linewidth=2)\n",
    "plt.plot(cnn_history.history['val_accuracy'], label='CNN Val Accuracy', linewidth=2)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Deep Learning Models Training History')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Feature importance (Random Forest)\n",
    "plt.subplot(2, 2, 4)\n",
    "top_features = feature_importance.head(10)\n",
    "plt.barh(range(len(top_features)), top_features['importance'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 10 Feature Importance (Random Forest)')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical significance testing\n",
    "from scipy import stats\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STATISTICAL ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Cross-validation scores\n",
    "cv_scores = {}\n",
    "models_cv = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(kernel='rbf', random_state=42),\n",
    "    'MLP': MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in models_cv.items():\n",
    "    scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "    cv_scores[name] = scores\n",
    "    print(f\"{name}: CV Accuracy = {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n",
    "\n",
    "print(\"\\nCross-Validation Results Summary:\")\n",
    "cv_df = pd.DataFrame({name: scores for name, scores in cv_scores.items()})\n",
    "print(cv_df.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
